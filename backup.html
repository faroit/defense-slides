<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/alabs.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/github.css">

		<script src="https://unpkg.com/wavesurfer.js"></script>

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
	<div class="reveal">
	<div class="slides">

	<section>
		<h2>Extended Slides</h2>
		<div class="container">
			<div class="col">
				Common Fate
			</div>
			<div class="col">
				SourceÂ Counting
			</div>
			<div class="col">
				Time Warping
			</div>
		</div>
	</section>

	<section>
		<h2>The big picture</h2>
		
		<div>$$\mathbf{x}=\sum_{j=1}^{k}\mathbf{s}_j$$</div>
		<div class="container">
			<div class="col" style='text-align: center'>
				<h3>Signal Processing</h3>
				<ul>
					<li>Can we obtain $\mathbf{s}_j$ from $\mathbf{x}$?</li>
					<li>Source Separation</li>
				</ul>
			</div>
			<div class="col" style='text-align: center'>
				<h3>Signal Analysis</h3>
				<ul>
					<li>Can we find $k$ from $\mathbf{x}$?</li>
					<li>Count Estimation</li>
				</ul>
			</div>
		</div>
	</section>

	<section>
		<h2>Outlook</h2>
		<ul>
			<li>Paradigm shift for AI
				<ul>
					<li>Domain knowledge will still be useful</li>
					<li>but: many problems can be solved without</li>
				</ul>
			</li>
			<p></p>
			<li>Source Separation
				<ul>
					<li>Representations learning</li>
					<li>Utilize long-term structure</li>
					<li>Generative models</li>
				</ul>
			</li>
			<li>Count estimation
				<ul>
					<li>Realistic Datasets</li>
					<li>Solving Extrapolation</li>
				</ul>
			</li>
			
		</ul>
	</section>

	<section>
		<h2>Model selection</h2>
		<img src="assets/images/countnet_parameters.svg" alt="">
	</section>

	<section>
		<section>
			<h2>Architectures</h2>
			<img width="120%" src="assets/images/architectures.svg" alt="">
		</section>
		<section>
			<h2>Architectures</h2>
			<img width="120%" src="assets/images/networkoverview.svg" alt="">
		</section>
		<section>
			<h2>CRNN</h2>
			<img width="120%" src="assets/images/nn.svg" alt="">
		</section>
	</section>

	<section>
		<h2>Applications</h2>
		<div class="container">
			<div class="col">
			<h3>Separation</h3>
				<ul>
					<li>Active Listening</li>
					<li>Music Repurposing</li>
					<li>Hearing Aids</li>
					<li>Frontend for many other signal processing methods</li>
				</ul>
			</div>
			<div class="col">
				<h3>Count Estimation</h3>
				<ul>
					<li>First step to address the separation</li>
					<li>Crowd Surveillance</li>
					<li>Wildlife Monitoring</li>
					<li>Frontend for Speech Recognition and Diarization</li>
				</ul>
			</div>
		</div>
	</section>

	<section data-background="#ED8C01" data-state="no-title-footer">
		<h1 style='color:white; font-size: 2.4em'>Source Separation</h1>
	</section>

	<section>
		<img width="120%" src="assets/images/trends.svg" alt="">
	</section>
	
	<section>
		<img width="120%" src="assets/images/duration.png" alt="">
	</section>

	<section>
		<h2>Scenario: Unison Separation</h2>
		<div class="container">
			<div class="col" style="text-align: center">
						<h3><img width="64px" src="assets/images/trumpet_icon.png" alt=""></h3>
						<div style="text-align: center">
							<img width="100%" src="assets/images/trumpet.svg">
						</div>

			</div>
		<div class="col">
			<div class="col" style="text-align: center">
				<h3><img width="64px" src="assets/images/cello_icon.png" alt=""></h3>
				<div style="text-align: center">
					<img width="100%" src="assets/images/cello.svg">
				</div>
			
			</div>
		</div>
		</div>
	</section>

	<section data-transition="slide fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<h3><img width="32px" src="assets/images/trumpet_icon.png" alt=""> Trumpet</h3>
		<div style="text-align: center" >
			<img width="80%" src="assets/images/trumpet.svg">
		</div>
	</section>

	<section data-transition="fade-in fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<h3><img width="32px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
		<div style="text-align: center">
			<img width="80%" src="assets/images/cello.svg">
		</div>
	</section>

	<section data-transition="fade-in fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<h3><img width="32px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
		<div style="text-align: center">
				<img width="80%" src="assets/images/cello_ani.svg">
		</div>
	</section>

	<section data-transition="fade-in fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<h3><img width="32px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
		<div style="text-align: center">
			<img width="80%" src="assets/images/cello.svg">
		</div>
	</section>

	<section data-transition="fade-in side">
		<h2>Instruments playing Unison</h2>
		<h3><img width="32px" src="assets/images/trumpet_icon.png" alt=""> Trumpet + <img width="32px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
		<div style="text-align: center">
				<img width="80%" src="assets/images/both.svg">
		</div>
	</section>
	
	<section>
		<h2>Research Question</h2>
		<ul>
			<li>Unison has extreme overlap</li>
			<li>Separation Sandbox</li>
		</ul>
	</br>
	</br>
		<p style="width: 50%; margin: auto; background-color: orange; padding: 10px; color:white">
			Can we utilize modulations for separation of unison mixtures?
		</p>
			</br>
			</br>

		<h3>Contributions</h3>
		<ul>
			<li>Known/Informed Modulation</li>
			<li>Unknown Modulation</li>
		</ul>
	</section>

	<section>
		<h2>Known Modulation</h2>
	</section>

	<section>
		<h2>Speaking Rate</h2>
		<img width="70%" src="assets/images/speaking_rate.svg" alt="">
	</section>

	<section>
		<h2>Extension for real world data</h2>
		<h3>Results SiSEC 2016</h3>
		<img src="assets/images/sisec17.svg" alt="">
		<ul>
			<li><a href="https://www.sisec17.audiolabs-erlangen.de/#/listen/21/STO1">DEMO</a></li>
		</ul>
	</section>
	<section>
		<section>
			<h2>Known Modulation</h2>
			<h3>Existing Models</h3>
	
			<div class="container">
				<div class="col">
					<ul>
						<li>Source/filter model <a class='ref' href="#">Durrieu 2010</a></li>
						<li>HR-NMF <a class='ref' href="#">Badeau 2011</a></li>
						<li>Modulation tensor <a class='ref' href="#">Barker 2013</a>
						</li>
					</ul>
					<h3>Proposed Model</h3>

				</div>
				<div class="col">
					<img style="float:right" width="100%" src="assets/images/ReviewPaper_ Figure2_new.svg" alt="">
				</div>
			</div>
		</section>
	
		<section>
			<h2>A brief history: model-driven methods</h2>
			<h3>Redundancy for the accompaniment: NMF</h3>
	
			<div class="container">
				<div class="col">
					<ul>
						<li>Spectral templates</li>
						<li>Low-rank assumptions</li>
						<li>Bad generalization</li>
					</ul>
				</div>
				<div class="col">
					<img height="60%" src="assets/images/ReviewPaper_ Figure3.svg" alt="">
				</div>
			</div>
	
		</section>
	
		<section>
			<h2>A brief history: model-driven methods</h2>
			<h3>Redundancy for the accompaniment: RPCA</h3>
			<div class="container">
				<div class="col">
					<ul>
						<li>Low-rank for music</li>
						<li>Vocals as unstructured</li>
						<li>Strong interferences in general</li>
					</ul>
				</div>
				<div class="col">
					<img src="assets/images/ReviewPaper_ Figure4.svg" alt="">
				</div>
			</div>
		</section>
	
		<section>
			<h2>A brief history: model-driven methods</h2>
			<h3>Redundancy for the accompaniment: REPET</h3>
			<div class="container">
				<div class="col">
					<ul>
						<li>Repetitive music</li>
						<li>Non-repetitive vocals</li>
						<li>Solos in vocals</li>
					</ul>
				</div>
				<div class="col">
					<img src="assets/images/ReviewPaper_ Figure5.svg" alt="">
				</div>
			</div>
		</section>
	
		<section>
			<h2>A brief history: model-driven methods</h2>
			<h3> Modeling both lead and accompaniment: source filter</h3>
	
			<div class="container">
				<div class="col">
					<ul>
						<li>Harmonic vocals</li>
						<li>Low-rank music</li>
						<li>Poor generalization</li>
					</ul>
				</div>
				<div class="col">
					<img src="assets/images/ReviewPaper_ Figure7.svg" alt="">
				</div>
			</div>
		</section>
	</section>
<!-- ----------------------------------------------------------------------------------------- -->


	<section data-background="assets/images/devons.png" data-state="no-title-footer">
	
	</section>


	<!-- ----------------------------------------------------------------------------------------- -->
	<section data-background="assets/images/flock.jpg" data-state="no-title-footer">
		<p style="background-color:rgba(255, 255, 255, .5) ; padding: 10px; color:black; margin-top: 15em">
			<strong>Common Fate Transform:</strong> groups common modulation textures to sound sources.
		</p>

	</section>

	<section>
		<h2>Step 1: Short-Time Fourier Transform</h2>
		<!-- TODO PLAY -->
		<div style="text-align: center">
				<img style="margin-left:-20px" width="70%" src="assets/images/stft.png">
		</div>
		<p style="text-align:center">
			$\mathbf{X} \in \mathbb{C}^{352 \times 279}$
		</p>
	</section>

	<section>
		<h2>Step 2: Common Fate Transform (CFT)</h2>
		<table>
			<tr>
				<td>
					<img src="assets/images/gft.png" width="100%" alt="" />
					<p style="text-align:center">
						STFT Grid
					</p>
					<p style="text-align:center">
						$\mathcal{G} \in \mathbb{C}^{32 \times 48 \times 11 \times 6}$
					</p>
				</td>
				<td>
					<img src="assets/images/cft.png" width="100%" alt="" />
					<p style="text-align:center">
						CFT
					</p>
					<p style="text-align:center">
						$\mathcal{V} \in \mathbb{C}^{32 \times 48 \times 11 \times 6}$
					</p>
				</td>
			</tr>
		</table>
		<p>
		</p>
	</section>

	<section>
		<h2>In Detail</h2>
		<img class="stretch" src="assets/images/gridplot.svg">
	</section>

	<section>
		<h2>Compared to modulation spectrograms... </h2>
		<ul>
			<li>CFT is computed using complex STFT $X$
				<ul>
					<li>Easily invertible</li>
					<li>Models phase dependencies between neighbouring STFT entries</li>
				</ul>
			</li>
			<li>Patches span/merge several frequency bins</li>
			<li>Results in <strong>modulation texture</strong></li>
		</ul>
	</section>

	<section>
		<section>
			<h2>Demo: Sax + Flute</h2>
			<iframe src="assets/audio/commonfate/66-73.html" class="stretch"></iframe>
		</section>
		<section>
			<h2>Demo: Viola + Flute</h2>
			<iframe src="assets/audio/commonfate/42-73.html" class="stretch"></iframe>
		</section>
	</section>

	<section>
		<h2>Extension for real world data</h2>
		<h3>SiSEC 2017</h3>
		<img src="assets/images/sisec17.svg" alt="">
	</section>

	<section>
		<h2>Summary</h2>
		<h3>Processing Methods for Separation</h3>
		<ul>
			<li>Unison Source Separation Scenario</li>
			<li>Importance of Modulations
				<ul>
					<li>Informed by $F_0$ to apply time warping</li>
					<li>Common Fate Representation for unknown modulations</li>
					<li>Common Fate Model, a suitable Factorization Model</li>
					<li>Deep Common Fate, supervised separation</li>
				</ul>
			</li>
		</ul>
	</section>

	<section>
		<h2>Further Contributions</h2>
		<div class="container">
			<div class="col" style="flex: 2">
			<h3>Data</h3>
			<ul>
				<li>Unison Dataset <a href="https://doi.org/10.5281/zenodo.1467921"><img
							src="https://zenodo.org/badge/DOI/10.5281/zenodo.1467921.svg" alt="DOI"></a>
				</li>
				<li>Cello Dataset <a href="https://doi.org/10.5281/zenodo.1560651"><img
							src="https://zenodo.org/badge/DOI/10.5281/zenodo.1560651.svg" alt="DOI"></a></li>
				<li>DSD100, MUSDB18 Dataset</li>
			</ul>
			<h3>Software Packages</h3>
			<ul>
				<li><a href="http://github.com/aliutkus/commonfate">commonfate</a></li>
				<li>musdb</li>
				<li>museval</li>
			</ul>
			<h3>Community</h3>
			<ul>
				<li>SiSEC Organization 2016, 2018</li>
				<li><a href="http://sisec17.audiolabs-erlangen.de">Interactive Evaluation</a></li>
			</ul>

			</div>
		
			<div class="col">
				
			</div>
		</div>
	</section>
	<section data-background="#ED8C01" data-state="no-title-footer">
		<h1 style='color:white; padding-right: 0px; font-size: 2.4em'>Source Count Estimation</h1>
	</section>

	<section>
			<div><h2>Open-Unmix</h2></div>
			<h3>State-of-the-art Music Separation 2019</h3>
	
			<div class="fig-container" data-file="http://umx-sisec18.s3-website.eu-west-3.amazonaws.com/"
				data-scroll="no" data-style="height: 430px; width: 800px;">
			</div>
		</section>

	<section>
		<h1>Separability</h1>
		<div style=text-align:center>
		<iframe width="850" height="600" seamless frameborder="0" scrolling="no"
			src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTHKuFERJtSQw870QDSr2e339Qt1qQ_O_F5r_wjpnB2Vq9oIul9fIfIHI6XdzU0uo1CCAxvFZSX0PeJ/pubchart?oid=220738334&amp;format=image"></iframe>
		</div>
	</section>

	<section>
		<h2>NTF Comparison of number of components</h2>
		<ul>
			<li>All factorisations ran for 100 iterations and were repeated five times.</li>
			<li>We chose $J = (2 \dots 6)$ components for each factorisation.</li>
			<li>For j > 2 we used oracle clustering by SDR</li>
		</ul>
	</section>
			
	<section>
		<h2>Dataset</h2>
		<ul>
			<li>Single pitches (C4 at 261.63 Hz)
				<ul>
					<li>Viola</li>
					<li>Cello</li>
					<li>Tenor sax</li>
					<li>English horn</li>
					<li>Flute</li>
				</ul>
			</li>
			<li>$\rightarrow$ ten mixtures of two instruments each</li>
			<li>Mixtures generated with a simple A â B â (A + B) scheme. </li>
			<li>Data were encoded in 44.1 kHz / 16 bit.</li>
		</ul>
	</section>

	<section>
		<h2>Common Fate Transform</h2>
		<img src="assets/images/cft_blocks.svg" width="100%" alt="" />
	</section>

	<section>
		<div class="container">
		
			<div class="col">
		<div class="fig-container" data-file="https://umxhq-demo.s3.eu-west-3.amazonaws.com/index.html" data-scroll="no"
			data-style="height: 40vh; width: 100%;">
		</div>

			</div>
		
			<div class="col">
		<div class="fig-container" data-file="https://umxpro-demo.s3.eu-west-3.amazonaws.com/index.html" data-scroll="no"
			data-style="height: 40vh; width: 100%;">
		</div>

			</div>
		</div>
	</section>

	<section>
		<h2>Number of Components</h2>
		<img src="assets/images/iterations.svg" width="100%" alt="" />
	</section>
			
	<section>
		<h2>Evaluation Results</h2>
		<img src="assets/images/boxplot.svg" width="100%" alt="" />
	</section>
	<section data-state="no-title-footer" data-background="#ED8C01">
		<h1 style='color:white; font-size: 2.4em'>Evaluation</h1>
	</section>

		<section>
			<h2>Common Fate Transform (CFT)</h2>
			<!-- TODO PLAY -->
			<div style="text-align: center">
				<img style="margin-left:-20px" width="70%" src="assets/images/stft.png">
			</div>
			<p style="text-align:center">
				$\mathbf{X} \in \mathbb{C}^{352 \times 279}$
			</p>
		</section>
		
		<section>
			<h2>Step s: Common Fate Transform (CFT)</h2>
			<table>
				<tr>
					<td>
						<img src="assets/images/gft.png" width="100%" alt="" />
						<p style="text-align:center">
							STFT Grid
						</p>
						<p style="text-align:center">
							$\mathcal{G} \in \mathbb{C}^{32 \times 48 \times 11 \times 6}$
						</p>
					</td>
					<td>
						<img src="assets/images/cft.png" width="100%" alt="" />
						<p style="text-align:center">
							CFT
						</p>
						<p style="text-align:center">
							$\mathcal{V} \in \mathbb{C}^{32 \times 48 \times 11 \times 6}$
						</p>
					</td>
				</tr>
			</table>
			<p>
			</p>
		</section>

	<section>
		<img width="120%" src="assets/images/duration.png" alt="">
	</section>

	<section>
		<h2>Parameters</h2>
		<ul>
			<li>STFT Window Size: $1024$</li>
			<li>STFT Hop Size: $512$</li>
			<li>CFM Window Size $(Na,Nb) = (4, 64)$</li>
			<li>CFM Hopsize $(Na,Nb) = (2, 32)$</li>
	
		</ul>
	</section>

	<section>
		<h2>Signal Separation</h2>
		<ol>
			<li>Compute the CFT from audio signal to get tensor $\mathcal{V}$</li>
			<li>Take the magnitude $|\mathcal{V}|$</li>
			<li>Initialise $\mathcal{A}$ and $\mathbf{h}$ with random non-negative values</li>
			<li>Apply multiplicative update rule to minimize $\beta$-divergence</strong></li>
			<li>Synthesise factorised components using Wiener filtering</strong></li>
			<li>Inverse CFT</strong></li>
		</ol>
	</section>
	<section>
		<h2>NMF</h2>
		<p>
			<img src="assets/images/nmf.svg" width="100%" alt="" />
			$$\sum\limits_{j=1}^{J} \mathbf{w}_{j}(f) \circ \mathbf{h}_{j}(t) $$
		</p>
	</section>
	<!-- ----------------------------------------------------------------------------------------- -->
	<section>
		<!-- ----------------------------------------------------------------------------------------- -->
		<section>
			<h2>Common Fate Model</h2>
			<p>
				<img src="assets/images/cfm_unfolded.svg" width="100%" alt="" />
				$$\sum\limits_{j=1}^{J} \mathcal{A}_{j}(a,b,f) \circ \mathbf{h}_{j}(t)$$
			</p>
		</section>
		<!-- ----------------------------------------------------------------------------------------- -->
		<section>
			<h2>Common Fate Model</h2>
			<p>
				<img src="assets/images/cfm.svg" width="100%" alt="" />
				$$\sum\limits_{j=1}^{J} \mathcal{A}_{j}(a,b,f) \circ \mathbf{h}_{j}(t)$$
			</p>
		</section>
		<!-- ----------------------------------------------------------------------------------------- -->
		<section>
			<h2>CPD/PARAFAC/NTF</h2>
			<!-- <ul>
									<li>Take the âouter-productâ of corresponding columns from each factor matrix to form a simple (rank-1) tensor</li>
								</ul> -->
			<p>
				<img src="assets/images/cpd.svg" width="100%" alt="" />
				$$\sum\limits_{j=1}^{J} \mathbf{w}_{j}(f) \circ \mathbf{m}_{j}(b) \circ \mathbf{h}_{j}(t)$$
			</p>
			<aside class="notes">
				<ul>
					<li>Can be extended to $n$-dimensions</li>
					$\sum\limits_{j=1}^{J} \mathbf{w}_{j}(f) \circ \mathbf{m}_{j}(b) \circ \mathbf{h}_{j}(t) \circ
					\mathbf{q}_{j}(t)$
				</ul>
			</aside>
		</section>
		<!-- ----------------------------------------------------------------------------------------- -->
	</section>
	
	<section>
		<h2>Evaluation Results</h2>
		<div class="container">
			<div class="col">
				<ul style="font-size: 24px">
					<li><strong>NMF</strong> Non-Negative Matrix Factorization</li>
					<li><strong>MOD</strong> CP on modulation spectrogram</li>
					<li><strong>CFM</strong> Common Fate Model
						<ul>
							<li><strong>CFMM</strong> Common Fate Magnitude Model</li>
							<li><strong>CFMMOD</strong> CFMM with $a=1$</li>
						</ul>
					</li>
					<li><strong>HR-NMF</strong> High Resolution NMF model</li>
				</ul>
			</div>
	
			<div class="col">
				<img src="assets/images/boxplot_justsdr.svg" width="80%" alt="" />
			</div>
		</div>
	</section>
	</div>
	<div class='footer'>
		<div id="copyright">Fabian-Robert StÃ¶ter</div>
		<img src="css/theme/alabs/alabs_logo.svg" alt="Logo" />
		<div id="middlebox">Separation and Count Estimation for Audio Sources Overlapping in Time and Frequency</div>
	</div>
	</div>

	<script src="js/reveal.js"></script>

	<script>
		// More info about config & dependencies:
		// - https://github.com/hakimel/reveal.js#configuration
		// - https://github.com/hakimel/reveal.js#dependencies
		// var wavesurfer = WaveSurfer.create({
		// 		container: '#waveform',
		// 		waveColor: 'grey',
		// 		progressColor: 'orange'
		// 	});
		// 	wavesurfer.load('assets/audio/fm_sine.wav');

		Reveal.initialize({
			math: {
				mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				TeX: {
					extensions: ["color.js"]
				}
			},
			controls: false,
			progress: true,
			history: true,
			center: false,
			slideNumber: true,
			minScale: 0.1,
			maxScale: 5,
			transition: 'none', //
			audio: {
				prefix: 'audio/', 	// audio files are stored in the "audio" folder
				suffix: '.wav',		// audio files have the ".ogg" ending
				textToSpeechURL: null,  // the URL to the text to speech converter
				defaultNotes: false, 	// use slide notes as default for the text to speech converter
				defaultText: false, 	// use slide text as default for the text to speech converter
				advance: -10, 		// advance to next slide after given time in milliseconds after audio has played, use negative value to not advance 
				autoplay: true,	// automatically start slideshow
				defaultDuration: 10,	// default duration in seconds if no audio is available 
				defaultAudios: false,	// try to play audios with names such as audio/1.2.ogg
			},
			dependencies: [
				{ src: 'plugin/markdown/marked.js' },
				{ src: 'plugin/markdown/markdown.js' },
				{ src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/math/math.js', async: true },
				{ src: 'node_modules/reveald3/reveald3.js' },
				{ src: 'plugin/audio-slideshow/audio-slideshow.js', condition: function () { return !!document.body.classList; } },
				{ src: 'plugin/highlight/highlight.js', async: true }
			]
		});

	</script>
	</body>
</html>
