<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/alabs.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/font-awesome/css/font-awesome.min.css">
		<link rel="stylesheet" href="lib/css/github.css">
		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
	<div class="reveal">
	<div class="slides">

	<section class="cover" data-background="css/theme/alabs/alabs_header.jpg" data-background-repeat="no-repeat" data-background-size="100%" data-background-position="0 0" data-state="no-title-footer no-progressbar">
		<h2>Separation and Count Estimation for Audio Sources Overlapping in Time and Frequency</h2>
		<h3>Ph.D. Presentation</h3>
		<p>
			Fabian-Robert StÃ¶ter<br />
		</p>
		<p>
			September 19th, 2019
		</p>
		<p>
		<div class='logos'>
			<img src="css/theme/alabs/FAU_bw.svg" id="FAU" class="logo" alt="">
			<img src="css/theme/alabs/IIS_bw.svg" id="IIS" class="logo" alt="">
		</div>
	</section>

	<section data-state="no-title-footer no-progressbar" data-background="black" data-state="no-title-footer" data-fullscreen>
		<div class="container">
			<div class="col fragment">
				<h1 style="color:#ED8C01">How many speakers do you hear?</h1>
				<div>
					<span class="fragment" data-audio-src="assets/audio/two_speaker_faded.wav"><h3>Example A</h3></span>
				</div>
				<div>
					<span class="fragment" data-audio-src="assets/audio/ten_speakers_faded.wav"><h3>Example B</h3></span>
				</div>
			</div>

			<div class="col fragment">
				<h1 style="color:lawngreen; margin-top: 6em">Can you focus on the individual instruments?</h1>
				<div>
					<span class="fragment" data-audio-src="assets/audio/jazz_wice.wav">
						<h3>Example A</h3>
					</span>
				</div>
				<div>
					<span class="fragment" data-audio-src="assets/audio/unison_wice.wav">
						<h3>Example B</h3>
					</span>
				</div>
			</div>
		</div>
		<aside class="notes">
			Good afternoon, it is an honor to welcome you to my defense especially...
			I would like to thank all members of the jury for coming today: The head of the jury, Professor Schober, My first examinier: Bernd, 2nd Gael Richard from ParisTech in France, and Michael Kohlhase from institute of Knowledge Representation/Processing.
		</aside>
	</section>

	<section>
		<h2>Overlap in Time and Frequency</h2>
		<div class="container">
			<div class="col">
				<img class="fragment step-fade-in-then-out" src="assets/images/overlap_00.svg"
					alt="">
				<img data-audio-src="assets/audio/00.wav" class="fragment fade-in-then-semi-out" src="assets/images/overlap_00.svg" alt=""></br>

				<img class="fragment step-fade-in-then-out" src="assets/images/overlap_01.svg" alt="">
				<img class="fragment fade-in-then-semi-out" data-audio-src="assets/audio/01.wav" src="assets/images/overlap_01.svg" alt="">
			</div>
			<div class="col">
				<img class="fragment step-fade-in-then-out" src="assets/images/overlap_10.svg" alt="">
				<img data-audio-src="assets/audio/10.wav" class="fragment fade-in-then-semi-out" src="assets/images/overlap_10.svg" alt=""></br>

				<img class="fragment step-fade-in-then-out" src="assets/images/overlap_11.svg" alt="">
				<img data-audio-src="assets/audio/11.wav" class="fragment fade-in-then-semi-out step-fade-in-then-out" src="assets/images/overlap_11.svg" alt="">
				<img class="fragment fade-in-then-semi-out step-fade-in-then-out" src="assets/images/overlap_11o.svg"
					alt="">
			</div>
		</div>
		<aside class="notes">
			I would like to explain the problems I am dealing with in this thesis by asking you two questions.
		</aside>
	</section>

	<section>
		<h2>The big picture</h2>
		
		<div style="text-align: center"><img width="650px" src="assets/images/mixture_model.svg" alt=""></div>
		<p></p>
		<div class="container">
			<div class="fragment col" style='margin-right: 2px; border:5px solid#00ADD8; padding: 0.6em; text-align: center'>
				<h3>Signal Processing</h3>
				<ul>
					<li>Can we obtain $\mathbf{s}_j$ from $\mathbf{x}$?</li>
					<li class='confirm'>Source Separation</li>
				</ul>
			</div>
			<div class="fragment col" style='border: 5px solid#F74949; padding: 0.6em; text-align: center'>
				<h3>Signal Analysis</h3>
				<ul>
					<li>Can we find $k$ from $\mathbf{x}$?</li>
					<li class="confirm">Count Estimation</li>
				</ul>
			</div>
		</div>
	</section>

	<section>
		<h2>Applications</h2>
		<div class="container">
			<div class="col">
			<h3>Separation</h3>
				<ul>
					<li>Active Listening</li>
					<li>Hearing Aids</li>
					<li>Frontend for many other signal processing methods</li>
				</ul>
			</div>
			<div class="col">
				<h3>Count Estimation</h3>
				<ul>
					<li>First step to address the separation</li>
					<li>Crowd Surveillance</li>
					<li>Wildlife Monitoring</li>
				</ul>
			</div>
		</div>
	</section>

	<section data-background="#00ADD8" data-state="no-title-footer">
		<h1 style='margin-top: 200px; color: white; font-size: 2.4em'>Source Separation</h1>
	</section>

	<section data-transition="slide fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<div style="text-align: center" >
				<h3><img width="48px" src="assets/images/trumpet_icon.png" alt=""> Trumpet</h3>
			<img data-audio-src="assets/audio/trumpet.wav" class="fragment step-fade-in-then-out" width="80%" src="assets/images/trumpet.svg">
			<img class="fragment step-fade-in-then-out" width="80%" src="assets/images/trumpet_o.svg">
		</div>
	</section>

	<section data-transition="fade-in fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<div style="text-align: center">
				<h3><img width="48px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
			<img class="fragment" data-audio-src="assets/audio/cellohigh.wav" width="80%" src="assets/images/cello.svg">
		</div>
	</section>

	<section data-transition="fade-in fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<div style="text-align: center">
				<h3><img width="48px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
				<img width="80%" src="assets/images/cello_ani.svg">
		</div>
	</section>

	<section data-transition="fade-in fade-out">
		<h2>Scenario: Instruments playing Unison</h2>
		<div style="text-align: center">
				<h3><img width="48px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
			<img width="80%" src="assets/images/cello.svg">
		</div>
	</section>

	<section data-transition="fade-in side">
		<h2>Instruments playing Unison</h2>
		<div style="text-align: center">
				<h3><img width="48px" src="assets/images/trumpet_icon.png" alt=""> Trumpet + <img width="48px" src="assets/images/cello_icon.png" alt=""> Cello</h3>
				<img class="fragment" data-audio-src="assets/audio/11.wav" width="80%" src="assets/images/both.svg">
		</div>
	</section>
	
	<section>
		<h2>Why is it difficult?</h2>
		<ul>
			<li>Unison has extreme overlap</li>
			<li>Toy example to study modulations</li>
			<li>Time-Frequency representations (e.g. STFT) are not sufficient</li>
		</ul>
	</br>
	</br>
		<p style="width: 60%; margin: auto; background-color: orange; padding: 10px; color:white">
			<span style="font-size:64px; float: left">ðŸ’¡</span>Can we utilize modulations for separation of unison mixtures?
		</p>
			</br>
			</br>

		<h3>Contributions</h3>
		<ul>
			<li>Known Modulation</li>
			<li>Unknown Modulation</li>
		</ul>
	</section>

	<section>
		<h2>Known Modulation</h2>	
		<div class="container fragment">
			<div class="col">
				<h3>$F_{0}$ informed separation</h3>
				<ul>
					<li>Spectral Comb Filter</li>
					<li>Informed non-negative matrix factorization (NMF)</li>
				</ul>
			</div>
			<div class="col" style="vertical-align: top">
				<img width="100%" src="assets/images/ReviewPaper_ Figure2_new.svg" alt="">
			</div>
		</div>
		<p></p>
		<div class="container fragment">
			<div class="col">
				<h3>Contribution</h3>
				<ul>
					<li>Use Time Warping</li>
					</li>
					<li>Filter in time domain
						<ul>
							<li>less artifacts</li>
							<li>required: accurate F0</li>
						</ul>
					</li>
		
				</ul>
			</div>
			<div class="col">
				<img width="100%" src="assets/images/ReviewPaper_ Figure2_new2.svg" alt="">
			</div>
		</div>
	</section>

	<section>
		<h2>MUSERC: MUlti SEnsor Recordings: Cello</h2>
		<video style="margin-top: -20px" controls autoplay loop>
			<source data-src="assets/video/cello.mp4" type="video/mp4" />
		</video>
	</section>

	<section>
		<h2>Unknown Modulation</h2>
		<div class="container fragment">
			<div>
				<h3>Joint modulation estimation and separation</h3>
				<ul>
					<li>Source/filter model</li>
					<li>HR-NMF (high resolution NMF)</li>
					<li>AM spectrogram factorization</li>
				</ul>
			</div>
		</div>
		<p></p>
		<div class="container fragment">
			<div>
				<h3>Contributions</h3>
				<ul>
					<li>Novel Representation</li>
					<li>Suitable Separation Model</li>
				</ul>
			</div>
		</div>
	</section>

	<section data-transition="none" data-background="assets/images/flocks.png" data-state="no-title-footer">
		<p style="background-color:rgba(255, 255, 255, .7) ; padding: 10px; color:black; margin-top: 15em">
			<strong>Common Fate:</strong> groups based on their common motion over time.</p>
	</section>

	<section data-transition="none" data-background-video="assets/video/flocks.mov" data-state="no-title-footer" data-background-video-muted>
		<p style="background-color:rgba(255, 255, 255, .7) ; padding: 10px; color:black; margin-top: 15em">
			<strong>Common Fate:</strong> groups based on their common motion over time.
		</p>
	</section>

		<section>
			<h2>Common Fate Transform (CFT)</h2>
			<!-- TODO PLAY -->
			<div style="text-align: center">
				<img class="stretch" src="assets/images/cft_blocks_streamlined.svg">
			</div>
			<ul>
				<li>CFT is computed using complex STFT
					<ul>
						<li>Easily invertible</li>
					</ul>
				</li>
				<li>Adequate for 2D-stationary <strong>texture</strong></li>
				<li>Separation using Non-Negative Tensor Factorization</li>
			</ul>
		</section>

	<!-- <section>
		<h2>In Detail</h2>
		<img class="stretch" src="assets/images/gridplot.svg">
	</section> -->

	<!-- <section>
		<h2>Common Fate Model (CFM)</h2>
			<p>
				<img src="assets/images/cfm_unfolded.svg" width="80%" alt="" />
				$$\sum\limits_{j=1}^{J} \mathcal{A}_{j}(a,b,f) \circ \mathbf{h}_{j}(t)$$
			</p>
			<ul>
				<li>Based on Non-Negative Tensor Factorization</li>
			</ul>
	</section> -->

	<section>
		<section>
			<h2>Demo: Sax + Flute</h2>
			<iframe src="assets/audio/commonfate/66-73.html" class="stretch"></iframe>
		</section>
		<section>
			<h2>Demo: Viola + Flute</h2>
			<iframe src="assets/audio/commonfate/42-73.html" class="stretch"></iframe>
		</section>
	</section>

	<section>
		<h2>Extending CFT for music separation</h2>
		<ul>
			<li>Common fate transform + Deep Neural Networks</li>
			<li>Model from <a href="#">Uhlich 2015</a></li>
			<li>Improvements compared to STFT</li>
			<li>Participated in SiSEC 2016</li>
		</ul>
		<p></p>
		<img width="80%" src="assets/images/uhlich_dnn.svg" alt="">
	</section>

		<!-- <section>
			<h2>Extension for real world data</h2>
			<h3>Results SiSEC 2016</h3>
			<img src="assets/images/sisec17.svg" alt="">
			<ul>
				<li><a href="https://www.sisec17.audiolabs-erlangen.de/#/listen/21/STO1">DEMO</a></li>
			</ul>
		</section> -->

	<!-- <section>
		<h2>Summary</h2>
		<h3>Processing Methods for Separation</h3>
		<ul>
			<li>Unison Source Separation Scenario</li>
			<li>Importance of Modulations
				<ul>
					<li>Informed by $F_0$ to apply time warping</li>
					<li>Common Fate Representation for unknown modulations</li>
					<li>Common Fate Model, a suitable Factorization Model</li>
					<li>Deep Common Fate, supervised separation</li>
				</ul>
			</li>
		</ul>
	</section>
 -->
	<section data-background="assets/images/devons_soft.jpg"  data-state="no-title-footer">
		<h1 style='margin-top: 200px; background-color: white; color: orange; font-size: 2.4em'>Source Count Estimation</h1>
	</section>

	<section>
		<h2>Strategies to Count</h2>
		<div class="container">
			<div class='col fragment' style="padding: 1em">
				<img src="assets/images/counting_detection.svg" alt=""></br>
			</div>
			<div class='col fragment' style="padding: 1em">
				<img src="assets/images/counting_estimation.svg" alt="">
			</div>
			<div class='col fragment' style="padding: 1em">
				<img src="assets/images/counting_subitizing.svg" alt="">
			</div>
		</div>

	</section>

	<section>
		<h2>Research Questions</h2>
		<ul>
			<li>What are the limitations of subitizing audio sources?</li>
			<li>Can we build a machine to address count estimation?</li>
			<li>Would a machine be subject to the same limitations?</li>
		</ul>
	</section>

		<section>
			<h2>Study on Music</h2>
			<h3>What is the number of instruments in music?</h3>
			<div class="container">
				<div class='col' style="font-size: 28px; padding-top: 1em">
					<ul>
						<li>12 music stimuli</li>
						<li>Unison for $k=2$</li>
						<li>Musicians vs. Non-Musicians</li>
						<li>lab ($n=40$) vs web ($n=1168$)</li>
					</ul>
				</div>
				<div class='col fragment step-fade-in-then-out'>
					<h1 style="padding: 1em; font-size: 100px">ðŸ”ˆ</h1>
				</div>
				<div class='col fragment step-fade-in-then-out' data-audio-src="assets/audio/jazz_wice.wav">
					<h1 style="padding: 1em; font-size: 100px">ðŸ”Š</h1>
				</div>
				<div class='col fragment step-fade-in-then-out' style="padding-top: 1em">
					<img src="assets/images/count_instr.svg" alt="">
				</div>
			</div>
		</section>

	<section>
		<h2>Study on Speech</h2>
		<h3>"What is the maximum number of concurrent speakers?"</h3>
			<div class="container">
				<div class='col' style="font-size: 28px; padding-top: 1em">
					<ul>
						<li>100 English stimuli (5s)</li>
						<li>n=40</li>
						<li>$k_{max}$ unknown (blind)</li>
						<li>$k_{max}$ known (blind)</li>
						<li>Confirm earlier study in japanese</li>
						<li>Experiment <a href="https://denumerate.app">denumerate.app</a></li>
					</ul>				
				</div>
				<div class='col fragment' style="padding-top: 1em">
					<img src="assets/images/speech_experiment.svg" alt="">
				</div>
			</div>
			<p class="fragment" style="font-size: 24px; width: 50%; margin: auto; background-color: orange; padding: 10px; color:white">
				Music and Speech: "One-Two-Three-Many"
			</p>
	</section>

	<section>
		<h2>Research Questions</h2>
		<ul>
			<li style="opacity: 0.5">What are the limitations of subitizing audio sources?</li>
			<li class='confirm'>Can we build a machine to address count estimation?</li>
			<li>Would a machine be subject to the same limitations?</li>
		</ul>
	</section>

	<section>
		<h2>Task definition</h2>
		<p></p>
		<div style="margin-top: 100px; text-align: center">

			<img src="assets/images/pipe.svg" width="60%" alt="">
		</div>
		<!-- <img src="assets/images/task.svg" alt=""> -->
		<p style="margin-top:120px"></p>
		<ul class="fragment">
			<li>$k$ = Maximum number of concurrent speaker in excerpt L</li>
			<li>Evaluation metric: mean absolute (count) error</li>
		</ul>
	</section>

	<section>
		<h2>Data-Driven Count Estimation</h2>
		<div style="text-align: center">
			<img width="50%" src="assets/images/train.svg" alt="">
		</div>
		<ul>
			<li>
				Synthetically overlapped mixtures using LibriSpeech
			</li>
			<li>
				20.020 training items (55h) ground truth labels
				<ul>
					<li>1820 samples for $[0 ... 10]$ speakers</li>
					<li>$k=0$ from TUT Acoustic Scenes dataset</li>
				</ul>
			</li>
		</ul>
	</section>

	<section>
		<h2>Design Decisions</h2>
		<img src="assets/images/params0.svg" class="fragment step-fade-in-then-out" width="100%" class="" alt="">
		<img src="assets/images/params1.svg" class="fragment step-fade-in-then-out" width="100%" class="" alt="">
		<img src="assets/images/params2.svg" class="fragment step-fade-in-then-out" width="100%" class="" alt="">
		<img src="assets/images/params3.svg" class="fragment step-fade-in-then-out" width="100%" class="" alt="">
	</section>

	<section>
		<h2>Complexity</h2>
		<div class="container">
			<div class="col">
				<img width="100%" src="assets/images/complexity.svg" alt="">
			</div>
			<div class="col">
				<ul style="font-size: 24px">
					<li class="fragment">CRNN: Best tradeoff Performance/Complexity</li>
					<li class="fragment">F-CRNN: Suitable for mobile applications</li>
					</k>
				</ul>
			</div>
		</div>
		<p class="fragment"
			style="font-size: 28px; width: 100%; margin: auto; background-color: orange; margin-top: 10px; padding: 10px; color:white">
			<strong>CountNet</strong>: STFT â†’ CRNN â†’ Classification
		</p>
	</section>

	<section>
		<h2>Results on Test set</h2>
		<div class="container">
			<div class="col">
				<ul style="font-size: 24px">
					<li class="fragment">Excellent voice activity detection</li>
					<li class="fragment">Overestimation between $2 < k < 6$</li> <li class="fragment">Error rarely larger than 2</li>
					</k>
				</ul>
			</div>
			<div class="col">
				<img width="100%" src="assets/images/responses.svg" alt="">
			</div>	
		</div>
	</section>

	<section>
		<h2>Comparison to Baselines</h2>

		<div class="container">
			<div class='col'>
				<div class="fig-container" data-file="assets/figures/original.html" data-style="height: 400px; width: 450px"></div>
				<h4>Train: LibriSpeech</br>
					Test: LibriSpeech
				</h4>

			</div>
			<div class='col fragment step-fade-in-then-out'>
				<ul style='font-size: 0.8em'>
					<li>MFCC7: K-Means on ${MFCC}[7]$</li>
					<li>SVM Classification on ${MFCC}_{20}$</li>
					<li>CRNN: DNN LSTM+CNN on STFT</li>
				</ul>
			</div>

		</div>
	</section>

	<section>
		<h2>Generalization Performance CountNet</h2>
		<div class="container" style="text-align: center">
			<div class='col'>
				<div class="fig-container" data-file="assets/figures/wow.html"
					data-style="height: 500px; width: 550px"></div>
			</div>
		</div>
	</section>

	<section>
		<h2>CountNet Demo</h2>
		<video controls loop>
			<source data-src="assets/video/countnet-demo.mp4" type="video/mp4" />
		</video>
	</section>

	<section>
		<h2>Research Questions</h2>
		<ul>
			<li style="opacity: 0.5">What are the limitations of subitizing audio sources?</li>
			<li style="opacity: 0.5">Can we build a machine to address count estimation?</li>
			<li class='confirm'>Would a machine be subject to the same limitations?</li>
		</ul>
	</section>

	<section>
		<h2>CountNet vs. Human</h2>
		<div class="container">
			<div class="col">
				<ul style="font-size: 36px">
					<li class="man fragment">Underestimation</li>
					<li class="machine fragment">Overestimation </li>
					<li class="man fragment">One-Two-Three-Many</li>
					<li class="machine fragment">One-...-$k_{max}$</li>
				</ul>
			</div>
			<div class="col">
				<img width="100%" src="assets/images/superhuman.svg" alt="">
			</div>
		</div>
	</section>

	<section data-background="assets/images/blackbox.jpg" data-state="no-title-footer">
	</section>

	<section>
		<h2>Understanding CountNet</h2>
		<div style="text-align: center" class="container fragment step-fade-in-then-out">
			<img width="80%" src="assets/images/input3.svg" alt="">
		</div>
		<div class="container fragment step-fade-in-then-out">
			<h3 style="margin-top: -20px">Convolutional Filters</h3>
			<img width="120%" src="assets/images/convfilters.svg" alt="">
		<p
			style="font-size: 24px; width: 50%; margin: auto; background-color: orange; padding: 10px; color:white">
			Does CountNet recognize phonemes?
		</p>

		</div>

	</section>

	<section>
		<h2>Understanding CountNet</h2>
		<h3 style="margin-top: -20px">Ablation Study</h3>
		<ul>
			<li>Using phonetic annotation in TIMIT dataset</li>	
			<li>Measure speaking rate</li>
			<li>Syllables per second => Modulation of Speech</li>
		</ul>
		<img width="90%" src="assets/images/phonemes.svg" alt="">
	</section>

	<section>
		<h2>Understanding CountNet</h2>

		<div class="container">
			<div class="col">
				<ul>
					<li>Retrained model on TIMIT</li>
					<li>Select k=6 items (balanced)</li>
					<li>Errors only <emph>underestimation</emph></li>
					<li class="confirm">Speaking rate has significant influence on the error</li>
				</ul>
			<p class="fragment" style="font-size: 24px; width: 70%; margin: auto; background-color: orange; margin-top: 20px; padding: 10px; color:white">
				CountNet used speech modulations
			</p>
			</div>

			<div class="col" style="flex: 0.5">
				<img width="70%" src="assets/images/speaking_rate.svg" alt="">
			</div>			
		</div>
	</section>

	<section>
		<h2>Conclusion</h2>
		<ul>
			<li class="fragment">Focus on overlapping part instead of non-overlapping part</li>
			<li class="fragment">Proposed methods for separating unison mixtures</li> 
			<li class="fragment">Extended Common Fate for music scenario</li>
			<li class="fragment">Speaker count estimation using Deep Learning</li>
			<li class="fragment">Studies showed CountNet outperformed humans</li>
			<li class="confirm fragment">Modulations play an important role audio tasks</li>
		</ul>
	</section>

	<section>
		<h2>Further Contributions</h2>
		<div class="container">
			<div class="col" style="flex: 2">
				<h3>Scientific</h3>
				<ul>
					<li>F0 Estimation using Warping</li>
					<li>Overview articles on music separation</li>
				</ul>
				<h3>Community service</h3>
				<ul>
					<li>Unison and Cello Dataset</li>
					<li>DSD100, MUSDB18 Dataset</li>
				</ul>
				<h3>Evaluation campaigns</h3>
				<ul>
					<li>Participations in SiSEC 2015, 2016</li>
					<li>SiSEC Organization 2016, 2018</li>
				</ul>
				<h3>Reproducibility</h3>
				<ul>
					<li><i class="fa fa-github"></i> commonfate, musdb, museval</li>
					<li><i class="fa fa-github"></i> SiSEC Websites, webMUSHRA</li>
				</ul>
	
			</div>
	
			<div class="col">
				<img height="60%" src="assets/images/other_contribs.png" alt="">
			</div>
		</div>
	</section>

	</div>
	<div class='footer'>
		<div id="copyright">Fabian-Robert StÃ¶ter</br>Ph.D. Presentation</div>
		<img src="css/theme/alabs/alabs_logo.svg" alt="Logo" />
		<div id="middlebox">Separation and Count Estimation for Audio Sources</br> Overlapping in Time and Frequency</div>
	</div>
	</div>

	<script src="js/reveal.js"></script>

	<script>

		Reveal.initialize({
			math: {
				mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				TeX: {
					extensions: ["color.js"]
				}
			},
				// specified using percentage units.
			width: 960,
			height: 700,
			controls: false,
			progress: true,
			history: true,
			center: false,
			slideNumber: true,
			minScale: 0.1,
			maxScale: 5,
			transition: 'none', //
			audio: {
				prefix: 'audio/', 	// audio files are stored in the "audio" folder
				suffix: '.wav',		// audio files have the ".ogg" ending
				textToSpeechURL: null,  // the URL to the text to speech converter
				defaultNotes: false, 	// use slide notes as default for the text to speech converter
				defaultText: false, 	// use slide text as default for the text to speech converter
				advance: -10, 		// advance to next slide after given time in milliseconds after audio has played, use negative value to not advance 
				autoplay: true,	// automatically start slideshow
				defaultDuration: 10,	// default duration in seconds if no audio is available 
				defaultAudios: false,	// try to play audios with names such as audio/1.2.ogg
			},
			dependencies: [
				{ src: 'plugin/markdown/marked.js' },
				{ src: 'plugin/markdown/markdown.js' },
				{ src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/math/math.js', async: true },
				{ src: 'plugin/reveald3/reveald3.js' },
				{ src: 'plugin/audio-slideshow/audio-slideshow.js', condition: function () { return !!document.body.classList; } },
				{ src: 'plugin/highlight/highlight.js', async: true }
			]
		});

	</script>
	</body>
</html>
